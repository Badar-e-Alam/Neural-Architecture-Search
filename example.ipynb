{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example to use HW-NAS-Bench under NAS-Bench-201's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_histogram(HW_metrics):\n",
    "    fpga_energy_values = [metrics[\"fpga_energy\"] for metrics in HW_metrics.values()]\n",
    "    plt.hist(fpga_energy_values, bins=10)\n",
    "    plt.xlabel(\"FPGA Energy\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Histogram of FPGA Energy\")\n",
    "    plt.show()\n",
    "\n",
    "                                                                        \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def config():\n",
    "    with open('config.json') as f:\n",
    "        config_data = json.load(f)\n",
    "    return config_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Example to get all the hardware metrics in the No.0,1,2 architectures under NAS-Bench-201's Space\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15625/15625 [00:00<00:00, 128286.89it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tqdm \n",
    "from hw_nas_bench_api import HWNASBenchAPI as HWAPI\n",
    "hw_api = HWAPI(\"HW-NAS-Bench-v1_0.pickle\", search_space=\"nasbench201\")\n",
    "data={}\n",
    "\n",
    "# Example to get all the hardware metrics in the No.0,1,2 architectures under NAS-Bench-201's Space\n",
    "print(\"===> Example to get all the hardware metrics in the No.0,1,2 architectures under NAS-Bench-201's Space\")\n",
    "engery_list=[]\n",
    "latency_list=[]\n",
    "network_info={}\n",
    "for idx in tqdm.tqdm(range(15625)):\n",
    "    for dataset in [\"cifar10\", \"cifar100\", \"ImageNet16-120\"]:\n",
    "        HW_metrics = hw_api.query_by_index(idx, dataset)\n",
    "        \n",
    "        if HW_metrics[\"fpga_energy\"] >0.02 and HW_metrics[\"fpga_latency\"] < 0.5:\n",
    "            network_info[idx]=dataset\n",
    "#         engery_list.append(HW_metrics[\"fpga_energy\"])\n",
    "        latency_list.append(HW_metrics[\"fpga_latency\"])\n",
    "# data[\"engery\"]=engery_list\n",
    "# data[\"latency\"]=latency_list\n",
    "        # print(\"The HW_metrics (type: {}) for No.{} @ {} under NAS-Bench-201: {}\".format(type(HW_metrics),\n",
    "        #                                                                        idx,\n",
    "        #                                                                        dataset,\n",
    "        #                                                                        HW_metrics[\"fpga_energy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean latency: 2.8663451852799637 max latency: 8.67856 min latency: 0.28432\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean latency: {sum(latency_list)/len(latency_list)} max latency: {max(latency_list)} min latency: {min(latency_list)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of networks with energy >1 or latency >5: 688\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of networks with energy >1 or latency >5: {len(network_info)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try to create the NAS-Bench-201 api from NAS-Bench-201-v1_0-e61699.pth\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "pickle data was truncated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/scratch-local/alam/HW-NAS-Bench/example.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcode57/scratch-local/alam/HW-NAS-Bench/example.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnas_201_api\u001b[39;00m \u001b[39mimport\u001b[39;00m NASBench201API \u001b[39mas\u001b[39;00m API\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcode57/scratch-local/alam/HW-NAS-Bench/example.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# Create an API without the verbose log\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcode57/scratch-local/alam/HW-NAS-Bench/example.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m api \u001b[39m=\u001b[39m API(\u001b[39m'\u001b[39;49m\u001b[39mNAS-Bench-201-v1_0-e61699.pth\u001b[39;49m\u001b[39m'\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcode57/scratch-local/alam/HW-NAS-Bench/example.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# The default path for benchmark file is '{:}/{:}'.format(os.environ['TORCH_HOME'], 'NAS-Bench-201-v1_1-096897.pth')\u001b[39;00m\n",
      "File \u001b[0;32m/scratch-local/alam/HW-NAS-Bench/nas_201_api/api_201.py:70\u001b[0m, in \u001b[0;36mNASBench201API.__init__\u001b[0;34m(self, file_path_or_dict, verbose)\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[39massert\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(file_path_or_dict), \u001b[39m'\u001b[39m\u001b[39minvalid path : \u001b[39m\u001b[39m{:}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(file_path_or_dict)\n\u001b[1;32m     69\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename \u001b[39m=\u001b[39m Path(file_path_or_dict)\u001b[39m.\u001b[39mname\n\u001b[0;32m---> 70\u001b[0m   file_path_or_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(file_path_or_dict, map_location\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     71\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(file_path_or_dict, \u001b[39mdict\u001b[39m):\n\u001b[1;32m     72\u001b[0m   file_path_or_dict \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(file_path_or_dict)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:1028\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1027\u001b[0m         \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1028\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:1256\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1254\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1255\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1256\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1258\u001b[0m deserialized_storage_keys \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39mload(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1260\u001b[0m offset \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mtell() \u001b[39mif\u001b[39;00m f_should_read_directly \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: pickle data was truncated"
     ]
    }
   ],
   "source": [
    "from nas_201_api import NASBench201API as API\n",
    "# Create an API without the verbose log\n",
    "api = API('NAS-Bench-201-v1_0-e61699.pth', verbose=True)\n",
    "# The default path for benchmark file is '{:}/{:}'.format(os.environ['TORCH_HOME'], 'NAS-Bench-201-v1_1-096897.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "pickle data was truncated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/scratch-local/alam/HW-NAS-Bench/example.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcode57/scratch-local/alam/HW-NAS-Bench/example.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcode57/scratch-local/alam/HW-NAS-Bench/example.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mNAS-Bench-201-v1_1-096897.pth\u001b[39;49m\u001b[39m'\u001b[39;49m,map_location\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mdevice(\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:1028\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1027\u001b[0m         \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1028\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:1256\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1254\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1255\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1256\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1258\u001b[0m deserialized_storage_keys \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39mload(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1260\u001b[0m offset \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mtell() \u001b[39mif\u001b[39;00m f_should_read_directly \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: pickle data was truncated"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.load('NAS-Bench-201-v1_1-096897.pth',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.9456"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Example to get use the hardware metrics in the No.0 architectures in CIFAR-10 under NAS-Bench-201's Space\n",
      "edgegpu_latency: 5.807418537139893 (ms)\n",
      "edgegpu_energy: 24.226614330768584 (mJ)\n",
      "raspi4_latency: 10.481976820010459 (ms)\n",
      "edgetpu_latency: 0.9571811309997429 (ms)\n",
      "pixel3_latency: 3.6058499999999998 (ms)\n",
      "eyeriss_latency: 3.645620000000001 (ms)\n",
      "eyeriss_energy: 0.6872827644999999 (mJ)\n",
      "eyeriss_arithmetic_intensity: 6.289297634665844 (mJ)\n",
      "fpga_latency: 2.57296 (ms)\n",
      "fpga_energy: 18.01072 (mJ)\n",
      "average_hw_metric: 591005.8676719831\n"
     ]
    }
   ],
   "source": [
    "# Example to get use the hardware metrics in the No.0 architectures in CIFAR-10 under NAS-Bench-201's Space\n",
    "print(\"===> Example to get use the hardware metrics in the No.0 architectures in CIFAR-10 under NAS-Bench-201's Space\")\n",
    "HW_metrics = hw_api.query_by_index(0, \"cifar10\")\n",
    "for k in HW_metrics:\n",
    "    if 'average' in k:\n",
    "        print(\"{}: {}\".format(k, HW_metrics[k]))\n",
    "        continue\n",
    "    elif \"latency\" in k:\n",
    "        unit = \"ms\"\n",
    "    else:\n",
    "        unit = \"mJ\"\n",
    "    print(\"{}: {} ({})\".format(k, HW_metrics[k], unit))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'infer.tiny', 'C': 16, 'N': 5, 'arch_str': '|avg_pool_3x3~0|+|nor_conv_1x1~0|skip_connect~1|+|nor_conv_1x1~0|skip_connect~1|skip_connect~2|', 'num_classes': 10}\n",
      "TinyNetwork(\n",
      "  TinyNetwork(C=16, N=5, L=17)\n",
      "  (stem): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (cells): ModuleList(\n",
      "    (0-4): 5 x InferCell(\n",
      "      info :: nodes=4, inC=16, outC=16, [1<-(I0-L0) | 2<-(I0-L1,I1-L2) | 3<-(I0-L3,I1-L4,I2-L5)], |avg_pool_3x3~0|+|nor_conv_1x1~0|skip_connect~1|+|nor_conv_1x1~0|skip_connect~1|skip_connect~2|\n",
      "      (layers): ModuleList(\n",
      "        (0): POOLING(\n",
      "          (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "        )\n",
      "        (1): ReLUConvBN(\n",
      "          (op): Sequential(\n",
      "            (0): ReLU()\n",
      "            (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): Identity()\n",
      "        (3): ReLUConvBN(\n",
      "          (op): Sequential(\n",
      "            (0): ReLU()\n",
      "            (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (4-5): 2 x Identity()\n",
      "      )\n",
      "    )\n",
      "    (5): ResNetBasicblock(\n",
      "      ResNetBasicblock(inC=16, outC=32, stride=2)\n",
      "      (conv_a): ReLUConvBN(\n",
      "        (op): Sequential(\n",
      "          (0): ReLU()\n",
      "          (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (conv_b): ReLUConvBN(\n",
      "        (op): Sequential(\n",
      "          (0): ReLU()\n",
      "          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (6-10): 5 x InferCell(\n",
      "      info :: nodes=4, inC=32, outC=32, [1<-(I0-L0) | 2<-(I0-L1,I1-L2) | 3<-(I0-L3,I1-L4,I2-L5)], |avg_pool_3x3~0|+|nor_conv_1x1~0|skip_connect~1|+|nor_conv_1x1~0|skip_connect~1|skip_connect~2|\n",
      "      (layers): ModuleList(\n",
      "        (0): POOLING(\n",
      "          (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "        )\n",
      "        (1): ReLUConvBN(\n",
      "          (op): Sequential(\n",
      "            (0): ReLU()\n",
      "            (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): Identity()\n",
      "        (3): ReLUConvBN(\n",
      "          (op): Sequential(\n",
      "            (0): ReLU()\n",
      "            (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (4-5): 2 x Identity()\n",
      "      )\n",
      "    )\n",
      "    (11): ResNetBasicblock(\n",
      "      ResNetBasicblock(inC=32, outC=64, stride=2)\n",
      "      (conv_a): ReLUConvBN(\n",
      "        (op): Sequential(\n",
      "          (0): ReLU()\n",
      "          (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (conv_b): ReLUConvBN(\n",
      "        (op): Sequential(\n",
      "          (0): ReLU()\n",
      "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (12-16): 5 x InferCell(\n",
      "      info :: nodes=4, inC=64, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2) | 3<-(I0-L3,I1-L4,I2-L5)], |avg_pool_3x3~0|+|nor_conv_1x1~0|skip_connect~1|+|nor_conv_1x1~0|skip_connect~1|skip_connect~2|\n",
      "      (layers): ModuleList(\n",
      "        (0): POOLING(\n",
      "          (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
      "        )\n",
      "        (1): ReLUConvBN(\n",
      "          (op): Sequential(\n",
      "            (0): ReLU()\n",
      "            (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): Identity()\n",
      "        (3): ReLUConvBN(\n",
      "          (op): Sequential(\n",
      "            (0): ReLU()\n",
      "            (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (4-5): 2 x Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lastact): Sequential(\n",
      "    (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (global_pooling): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the network\n",
    "config = hw_api.get_net_config(0, \"cifar10\")\n",
    "print(config)\n",
    "from hw_nas_bench_api.nas_201_models import get_cell_based_tiny_net\n",
    "network = get_cell_based_tiny_net(config) # create the network from configurration\n",
    "print(network) # show the structure of this architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example to use HW-NAS-Bench under FBNet's Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Example to get all the hardware metrics in the No.0,1,2 architectures under FBNet's Space\n",
      "The HW_metrics (type: <class 'dict'>) for No.[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] @ cifar100 under NAS-Bench-201: {'edgegpu_latency': 15.804523468017578, 'edgegpu_energy': 86.98095934380125, 'raspi4_latency': 17.618579145142576, 'pixel3_latency': 7.788973100000002, 'eyeriss_latency': 3.9408960000000004, 'eyeriss_energy': 3.2420080000000002, 'fpga_latency': 10.739520000000002, 'fpga_energy': 75.17664, 'average_hw_metric': 1945958271.4210253}\n",
      "The HW_metrics (type: <class 'dict'>) for No.[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] @ ImageNet under NAS-Bench-201: {'edgegpu_latency': 16.431164979934692, 'edgegpu_energy': 102.71604275841212, 'raspi4_latency': 57.65650005702628, 'pixel3_latency': 27.5423871, 'eyeriss_latency': 18.127332000000003, 'eyeriss_energy': 16.945472000000002, 'fpga_latency': 29.42189999999999, 'fpga_energy': 205.95329999999998, 'average_hw_metric': 4988655551037.17}\n",
      "The HW_metrics (type: <class 'dict'>) for No.[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] @ cifar100 under NAS-Bench-201: {'edgegpu_latency': 16.861193418502808, 'edgegpu_energy': 92.50940989292691, 'raspi4_latency': 17.505280663142912, 'pixel3_latency': 7.673164100000002, 'eyeriss_latency': 3.9004160000000003, 'eyeriss_energy': 3.2549479999999997, 'fpga_latency': 10.347840000000001, 'fpga_energy': 72.43488, 'average_hw_metric': 1993747792.0823224}\n",
      "The HW_metrics (type: <class 'dict'>) for No.[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] @ ImageNet under NAS-Bench-201: {'edgegpu_latency': 17.092111825942993, 'edgegpu_energy': 106.13277487508154, 'raspi4_latency': 57.98271677602315, 'pixel3_latency': 27.229345099999996, 'eyeriss_latency': 18.078716, 'eyeriss_energy': 16.862542, 'fpga_latency': 28.491659999999992, 'fpga_energy': 199.44161999999997, 'average_hw_metric': 4961410646784.242}\n",
      "The HW_metrics (type: <class 'dict'>) for No.[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1] @ cifar100 under NAS-Bench-201: {'edgegpu_latency': 18.126894235610962, 'edgegpu_energy': 99.01054894461463, 'raspi4_latency': 17.43969264414045, 'pixel3_latency': 7.596349100000001, 'eyeriss_latency': 3.8665600000000007, 'eyeriss_energy': 3.263408, 'fpga_latency': 10.07136, 'fpga_energy': 70.49952, 'average_hw_metric': 2130193321.381353}\n",
      "The HW_metrics (type: <class 'dict'>) for No.[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1] @ ImageNet under NAS-Bench-201: {'edgegpu_latency': 17.267947673797607, 'edgegpu_energy': 107.06404927999472, 'raspi4_latency': 58.2021167500061, 'pixel3_latency': 27.044592099999996, 'eyeriss_latency': 18.063916000000003, 'eyeriss_energy': 16.806142, 'fpga_latency': 27.835019999999993, 'fpga_energy': 194.84513999999996, 'average_hw_metric': 4791424545249.201}\n"
     ]
    }
   ],
   "source": [
    "# The index in FBNet Space is not a number but a list with 22 elements, and each element is from 0~8\n",
    "from hw_nas_bench_api import HWNASBenchAPI as HWAPI\n",
    "hw_api = HWAPI(\"HW-NAS-Bench-v1_0.pickle\", search_space=\"fbnet\")\n",
    "\n",
    "# Example to get all the hardware metrics in 3 specfic architectures under FBNet's Space\n",
    "print(\"===> Example to get all the hardware metrics in the No.0,1,2 architectures under FBNet's Space\")\n",
    "for idx in [[0]*22, [0]*21+[1]*1, [0]*20+[1]*2]:\n",
    "    for dataset in [\"cifar100\", \"ImageNet\"]:\n",
    "        HW_metrics = hw_api.query_by_index(idx, dataset)\n",
    "        print(\"The HW_metrics (type: {}) for No.{} @ {} under NAS-Bench-201: {}\".format(type(HW_metrics),\n",
    "                                                                               idx,\n",
    "                                                                               dataset,\n",
    "                                                                               HW_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Example to get use the hardware metrics in the No.0 architectures in ImageNet under FBNet's Space\n",
      "edgegpu_latency: 15.804523468017578 (ms)\n",
      "edgegpu_energy: 86.98095934380125 (mJ)\n",
      "raspi4_latency: 17.618579145142576 (ms)\n",
      "pixel3_latency: 7.788973100000002 (ms)\n",
      "eyeriss_latency: 3.9408960000000004 (ms)\n",
      "eyeriss_energy: 3.2420080000000002 (mJ)\n",
      "fpga_latency: 10.739520000000002 (ms)\n",
      "fpga_energy: 75.17664 (mJ)\n",
      "average_hw_metric: 1945958271.4210253\n"
     ]
    }
   ],
   "source": [
    "# Example to get use the hardware metrics in one specific architectures in ImageNet under FBNet's Space\n",
    "print(\"===> Example to get use the hardware metrics in the No.0 architectures in ImageNet under FBNet's Space\")\n",
    "HW_metrics = hw_api.query_by_index([0]*22, \"cifar100\")\n",
    "for k in HW_metrics:\n",
    "    if 'average' in k:\n",
    "        print(\"{}: {}\".format(k, HW_metrics[k]))\n",
    "        continue\n",
    "    elif \"latency\" in k:\n",
    "        unit = \"ms\"\n",
    "    else:\n",
    "        unit = \"mJ\"\n",
    "    print(\"{}: {} ({})\".format(k, HW_metrics[k], unit))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': 'cifar100', 'num_classes': 100, 'op_idx_list': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'arch_str': ['k3_e1', 'k3_e1', 'k3_e1', 'k3_e1', 'k3_e1', 'k3_e1', 'k3_e1', 'k3_e1', 'k3_e1', 'k3_e1', 'k3_e1', 'k3_e1', 'k3_e1', 'k3_e1', 'k3_e1', 'k3_e1', 'k3_e1', 'k3_e1', 'k3_e1', 'k3_e1', 'k3_e1', 'k3_e1']}\n",
      "FBNet_Infer(\n",
      "  (stem): ConvNorm(\n",
      "    (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (cells): ModuleList(\n",
      "    (0): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): ConvBlock(\n",
      "      (conv1): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): ConvBlock(\n",
      "      (conv1): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): ConvBlock(\n",
      "      (conv1): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): ConvBlock(\n",
      "      (conv1): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): ConvBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): ConvBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): ConvBlock(\n",
      "      (conv1): Conv2d(112, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=112, bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(112, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): ConvBlock(\n",
      "      (conv1): Conv2d(112, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=112, bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(112, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): ConvBlock(\n",
      "      (conv1): Conv2d(112, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=112, bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(112, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): ConvBlock(\n",
      "      (conv1): Conv2d(112, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=112, bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(112, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (18): ConvBlock(\n",
      "      (conv1): Conv2d(184, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "      (bn2): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(184, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (19): ConvBlock(\n",
      "      (conv1): Conv2d(184, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "      (bn2): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(184, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (20): ConvBlock(\n",
      "      (conv1): Conv2d(184, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "      (bn2): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(184, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "    (21): ConvBlock(\n",
      "      (conv1): Conv2d(184, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "      (bn2): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(184, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (nl): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (header): ConvNorm(\n",
      "    (conv): Conv2d(352, 1504, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (fc): Linear(in_features=1504, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the network\n",
    "config = hw_api.get_net_config([0]*22, \"cifar100\")\n",
    "print(config)\n",
    "from hw_nas_bench_api.fbnet_models import FBNet_Infer\n",
    "network = FBNet_Infer(config) # create the network from configurration\n",
    "print(network) # show the structure of this architecture"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
