{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ea12c45",
   "metadata": {},
   "source": [
    "Example of simple network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de61917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=64, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=16, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def create_neural_network(input_dims, output_dims, hidden_dims=[64, 32], activation=nn.ReLU()):\n",
    "    layers = []\n",
    "    \n",
    "    # Add input layer\n",
    "    layers.append(nn.Linear(input_dims, hidden_dims[0]))\n",
    "    layers.append(activation)\n",
    "    \n",
    "    # Add hidden layers\n",
    "    for i in range(1, len(hidden_dims)):\n",
    "        layers.append(nn.Linear(hidden_dims[i-1], hidden_dims[i]))\n",
    "        layers.append(activation)\n",
    "    \n",
    "    # Add output layer\n",
    "    layers.append(nn.Linear(hidden_dims[-1], output_dims))\n",
    "    \n",
    "    # Create the neural network\n",
    "    model = nn.Sequential(*layers)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "input_dims = 10\n",
    "output_dims = 5\n",
    "hidden_dims = [64, 32, 16]  # You can adjust the number of hidden layers and their sizes\n",
    "activation = nn.ReLU()\n",
    "\n",
    "net = create_neural_network(input_dims, output_dims, hidden_dims, activation)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06484342",
   "metadata": {},
   "source": [
    "Creating complex network with residual network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "577c18a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComplexNeuralNetwork(\n",
      "  (network): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): ResidualBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): Flatten(start_dim=1, end_dim=-1)\n",
      "    (6): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (10): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=32, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.stride != 1 or identity.shape[1] != out.shape[1]:\n",
    "            identity = nn.Conv2d(identity.shape[1], out.shape[1], kernel_size=1, stride=self.stride, bias=False)(identity)\n",
    "            identity = nn.BatchNorm2d(out.shape[1])(identity)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ComplexNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims, conv_channels=[16, 32], hidden_dims=[64, 32], activation=nn.ReLU()):\n",
    "        super(ComplexNeuralNetwork, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        # Initial convolutional layer\n",
    "        layers.append(nn.Conv2d(in_channels=input_dims, out_channels=conv_channels[0], kernel_size=3, padding=1))\n",
    "        layers.append(nn.BatchNorm2d(conv_channels[0]))\n",
    "        layers.append(activation)\n",
    "        \n",
    "        # Convolutional layers with skip connections (using ResidualBlocks)\n",
    "        in_channels = conv_channels[0]\n",
    "        for out_channels in conv_channels:\n",
    "            layers.append(ResidualBlock(in_channels, out_channels))\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        # Flatten the output of the convolutional layers\n",
    "        layers.append(nn.Flatten())\n",
    "        \n",
    "        # Linear layers with skip connections\n",
    "        in_features = in_channels\n",
    "        for out_features in hidden_dims:\n",
    "            layers.append(nn.Linear(in_features, out_features))\n",
    "            layers.append(nn.BatchNorm1d(out_features))\n",
    "            layers.append(activation)\n",
    "            in_features = out_features\n",
    "        \n",
    "        # Output linear layer\n",
    "        layers.append(nn.Linear(in_features, output_dims))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Example usage\n",
    "input_dims = 1  # Number of input channels (e.g., for RGB images)\n",
    "output_dims = 10  # Number of output classes\n",
    "conv_channels = [16, 32]  # Number of channels in convolutional layers\n",
    "hidden_dims = [64, 32]  # Sizes of hidden linear layers\n",
    "activation = nn.ReLU()\n",
    "\n",
    "net = ComplexNeuralNetwork(input_dims, output_dims, conv_channels, hidden_dims, activation).to(\"cuda\")\n",
    "\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4094c43",
   "metadata": {},
   "source": [
    "Downloading the training and validation dataset cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52c31dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transform)\n",
    "test_dataset = datasets.MNIST('../data', train=False,\n",
    "                   transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a7634c-f240-438a-ac0d-f481d226671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f98db0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f35e480",
   "metadata": {},
   "source": [
    "Specifing the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979362b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-31 23:42:59] INFO     <21732> evotorch.core: Instance of `SupervisedNE` (id:1977066052304) -- The `dtype` for the problem's decision variables is set as torch.float32\n",
      "[2023-08-31 23:42:59] INFO     <21732> evotorch.core: Instance of `SupervisedNE` (id:1977066052304) -- `eval_dtype` (the dtype of the fitnesses and evaluation data) is set as torch.float32\n",
      "[2023-08-31 23:42:59] INFO     <21732> evotorch.core: Instance of `SupervisedNE` (id:1977066052304) -- The `device` of the problem is set as cpu\n",
      "[2023-08-31 23:42:59] INFO     <21732> evotorch.core: Instance of `SupervisedNE` (id:1977066052304) -- The number of actors that will be allocated for parallelized evaluation is 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 23:43:03,782\tINFO worker.py:1621 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "from evotorch.neuroevolution import SupervisedNE\n",
    "\n",
    "mnist_problem = SupervisedNE(\n",
    "    train_dataset,  # Using the dataset specified earlier\n",
    "    net,  # Training the MNIST30K module designed earlier\n",
    "    nn.CrossEntropyLoss(),  # Minimizing CrossEntropyLoss\n",
    "    minibatch_size = 256,  # With a minibatch size of 256\n",
    "    common_minibatch = True,  # Always using the same minibatch across all solutions on an actor\n",
    "    num_actors = 4,  # The total number of CPUs used\n",
    "    num_gpus_per_actor = 'max',  # Dividing all available GPUs between the 4 actors\n",
    "    subbatch_size = 50,  # Evaluating solutions in sub-batches of size 50 ensures we won't run out of GPU memory for individual workers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301e65c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evotorch.algorithms import SNES\n",
    "searcher = SNES(mnist_problem, stdev_init = 1, popsize = 1000, distributed = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24008c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evotorch.logging import StdOutLogger, PandasLogger\n",
    "stdout_logger = StdOutLogger(searcher, interval = 1)\n",
    "pandas_logger = PandasLogger(searcher, interval = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2623dbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(EvaluationActor pid=31364)\u001b[0m c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py:3425: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "\u001b[2m\u001b[36m(EvaluationActor pid=31364)\u001b[0m   shares_storage = self._data.storage().data_ptr() == source._data.storage().data_ptr()\n"
     ]
    },
    {
     "ename": "RayTaskError(RuntimeError)",
     "evalue": "\u001b[36mray::EvaluationActor.call()\u001b[39m (pid=15768, ip=127.0.0.1, actor_id=ec842f8f74d2885b086432b201000000, repr=<evotorch.core.EvaluationActor object at 0x000001F4AF18C250>)\n  File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n    return method(self, *_args, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 185, in call\n    return getattr(self._problem, method_name)(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 3074, in _sample_and_compute_gradients\n    resulting_batch = sample_evaluated_batch()\n                      ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 3067, in sample_evaluated_batch\n    self.evaluate(batch)\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 2395, in evaluate\n    self._evaluate_all(batch)\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 2413, in _evaluate_all\n    self._evaluate_batch(batch)\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\supervisedne.py\", line 345, in _evaluate_batch\n    return super()._evaluate_batch(batch)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 2447, in _evaluate_batch\n    self._evaluate(sln)\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\neproblem.py\", line 424, in _evaluate\n    fitnesses = evaluator(self.parameterize_net(parameters))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\supervisedne.py\", line 338, in _evaluate_network\n    loss += self._evaluate_using_minibatch(network, self._current_minibatch) / self._num_minibatches\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\supervisedne.py\", line 264, in _evaluate_using_minibatch\n    yhat = network(x)\n           ^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_9976\\2304762305.py\", line 67, in forward\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 217, in forward\n    input = module(input)\n            ^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_9976\\2304762305.py\", line 25, in forward\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 463, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 459, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRayTaskError(RuntimeError)\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m searcher\u001b[39m.\u001b[39;49mrun(\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\algorithms\\searchalgorithm.py:425\u001b[0m, in \u001b[0;36mSearchAlgorithm.run\u001b[1;34m(self, num_generations, reset_first_step_datetime)\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_first_step_datetime()\n\u001b[0;32m    424\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mint\u001b[39m(num_generations)):\n\u001b[1;32m--> 425\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    427\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_end_of_run_hook) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    428\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_end_of_run_hook(\u001b[39mdict\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus))\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\algorithms\\searchalgorithm.py:390\u001b[0m, in \u001b[0;36mSearchAlgorithm.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_step_datetime \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_step_datetime \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m--> 390\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step()\n\u001b[0;32m    391\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    392\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_status({\u001b[39m\"\u001b[39m\u001b[39miter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_count})\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\algorithms\\distributed\\gaussian.py:202\u001b[0m, in \u001b[0;36mGaussianSearchAlgorithm._step_distributed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_step_distributed\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    200\u001b[0m     \u001b[39m# Use the problem object's `sample_and_compute_gradients` method\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[39m# to do parallelized and distributed gradient computation\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m     fetched \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproblem\u001b[39m.\u001b[39;49msample_and_compute_gradients(\n\u001b[0;32m    203\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distribution,\n\u001b[0;32m    204\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_popsize,\n\u001b[0;32m    205\u001b[0m         popsize_max\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_popsize_max,\n\u001b[0;32m    206\u001b[0m         obj_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_obj_index,\n\u001b[0;32m    207\u001b[0m         num_interactions\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_interactions,\n\u001b[0;32m    208\u001b[0m         ranking_method\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ranking_method,\n\u001b[0;32m    209\u001b[0m         ensure_even_popsize\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_even_popsize,\n\u001b[0;32m    210\u001b[0m     )\n\u001b[0;32m    212\u001b[0m     \u001b[39m# The method `sample_and_compute_gradients(...)` returns a list of dictionaries, each dictionary being\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[39m# the result of a different remote computation.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# For each remote computation, the list will contain a dictionary that looks like this:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[39m# mean_eval.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[39m# These lists will be stored by the following temporary class:\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[39mclass\u001b[39;00m \u001b[39mlist_of\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py:2797\u001b[0m, in \u001b[0;36mProblem.sample_and_compute_gradients\u001b[1;34m(self, distribution, popsize, num_interactions, popsize_max, obj_index, ranking_method, with_stats, ensure_even_popsize)\u001b[0m\n\u001b[0;32m   2794\u001b[0m dist_on_cpu \u001b[39m=\u001b[39m distribution\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2796\u001b[0m \u001b[39m# Here, we use our actor pool to execute our tasks in parallel.\u001b[39;00m\n\u001b[1;32m-> 2797\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\n\u001b[0;32m   2798\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_actor_pool\u001b[39m.\u001b[39;49mmap_unordered(\n\u001b[0;32m   2799\u001b[0m         (\n\u001b[0;32m   2800\u001b[0m             \u001b[39mlambda\u001b[39;49;00m a, v: a\u001b[39m.\u001b[39;49mcall\u001b[39m.\u001b[39;49mremote(\n\u001b[0;32m   2801\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39m_sample_and_compute_gradients\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   2802\u001b[0m                 [dist_on_cpu, v[\u001b[39m0\u001b[39;49m]],\n\u001b[0;32m   2803\u001b[0m                 {\n\u001b[0;32m   2804\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39mobj_index\u001b[39;49m\u001b[39m\"\u001b[39;49m: obj_index,\n\u001b[0;32m   2805\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39mnum_interactions\u001b[39;49m\u001b[39m\"\u001b[39;49m: v[\u001b[39m1\u001b[39;49m],\n\u001b[0;32m   2806\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39mpopsize_max\u001b[39;49m\u001b[39m\"\u001b[39;49m: v[\u001b[39m2\u001b[39;49m],\n\u001b[0;32m   2807\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39mranking_method\u001b[39;49m\u001b[39m\"\u001b[39;49m: ranking_method,\n\u001b[0;32m   2808\u001b[0m                 },\n\u001b[0;32m   2809\u001b[0m             )\n\u001b[0;32m   2810\u001b[0m         ),\n\u001b[0;32m   2811\u001b[0m         \u001b[39mlist\u001b[39;49m(\u001b[39mzip\u001b[39;49m(popsize_per_task, num_inter_per_task, popsize_max_per_task)),\n\u001b[0;32m   2812\u001b[0m     )\n\u001b[0;32m   2813\u001b[0m )\n\u001b[0;32m   2815\u001b[0m \u001b[39m# At this point, all the tensors within our collected results are on the CPU.\u001b[39;00m\n\u001b[0;32m   2817\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mdevice(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice) \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m   2818\u001b[0m     \u001b[39m# If the main device of this problem instance is not CPU, then we move the tensors to the main device.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\ray\\util\\actor_pool.py:161\u001b[0m, in \u001b[0;36mActorPool.map_unordered.<locals>.get_generator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_generator\u001b[39m():\n\u001b[0;32m    160\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_next():\n\u001b[1;32m--> 161\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_next_unordered()\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\ray\\util\\actor_pool.py:361\u001b[0m, in \u001b[0;36mActorPool.get_next_unordered\u001b[1;34m(self, timeout, ignore_if_timedout)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[39mif\u001b[39;00m raise_timeout_after_ignore:\n\u001b[0;32m    358\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m(\n\u001b[0;32m    359\u001b[0m         timeout_msg \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m. The task \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m has been ignored.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(future)\n\u001b[0;32m    360\u001b[0m     )\n\u001b[1;32m--> 361\u001b[0m \u001b[39mreturn\u001b[39;00m ray\u001b[39m.\u001b[39;49mget(future)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py:24\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mauto_init_wrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     23\u001b[0m     auto_init_ray()\n\u001b[1;32m---> 24\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[0;32m    102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\ray\\_private\\worker.py:2524\u001b[0m, in \u001b[0;36mget\u001b[1;34m(object_refs, timeout)\u001b[0m\n\u001b[0;32m   2522\u001b[0m     worker\u001b[39m.\u001b[39mcore_worker\u001b[39m.\u001b[39mdump_object_store_memory_usage()\n\u001b[0;32m   2523\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, RayTaskError):\n\u001b[1;32m-> 2524\u001b[0m     \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mas_instanceof_cause()\n\u001b[0;32m   2525\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2526\u001b[0m     \u001b[39mraise\u001b[39;00m value\n",
      "\u001b[1;31mRayTaskError(RuntimeError)\u001b[0m: \u001b[36mray::EvaluationActor.call()\u001b[39m (pid=15768, ip=127.0.0.1, actor_id=ec842f8f74d2885b086432b201000000, repr=<evotorch.core.EvaluationActor object at 0x000001F4AF18C250>)\n  File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n  File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n    return method(self, *_args, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 185, in call\n    return getattr(self._problem, method_name)(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 3074, in _sample_and_compute_gradients\n    resulting_batch = sample_evaluated_batch()\n                      ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 3067, in sample_evaluated_batch\n    self.evaluate(batch)\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 2395, in evaluate\n    self._evaluate_all(batch)\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 2413, in _evaluate_all\n    self._evaluate_batch(batch)\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\supervisedne.py\", line 345, in _evaluate_batch\n    return super()._evaluate_batch(batch)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 2447, in _evaluate_batch\n    self._evaluate(sln)\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\neproblem.py\", line 424, in _evaluate\n    fitnesses = evaluator(self.parameterize_net(parameters))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\supervisedne.py\", line 338, in _evaluate_network\n    loss += self._evaluate_using_minibatch(network, self._current_minibatch) / self._num_minibatches\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\supervisedne.py\", line 264, in _evaluate_using_minibatch\n    yhat = network(x)\n           ^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_9976\\2304762305.py\", line 67, in forward\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 217, in forward\n    input = module(input)\n            ^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_9976\\2304762305.py\", line 25, in forward\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 463, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 459, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-31 23:27:58,918\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::EvaluationActor.call()\u001b[39m (pid=31376, ip=127.0.0.1, actor_id=c3fbdfbe427049d95e21120501000000, repr=<evotorch.core.EvaluationActor object at 0x000001E80F282090>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 185, in call\n",
      "    return getattr(self._problem, method_name)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 3074, in _sample_and_compute_gradients\n",
      "    resulting_batch = sample_evaluated_batch()\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 3067, in sample_evaluated_batch\n",
      "    self.evaluate(batch)\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 2395, in evaluate\n",
      "    self._evaluate_all(batch)\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 2413, in _evaluate_all\n",
      "    self._evaluate_batch(batch)\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\supervisedne.py\", line 345, in _evaluate_batch\n",
      "    return super()._evaluate_batch(batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 2447, in _evaluate_batch\n",
      "    self._evaluate(sln)\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\neproblem.py\", line 424, in _evaluate\n",
      "    fitnesses = evaluator(self.parameterize_net(parameters))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\supervisedne.py\", line 338, in _evaluate_network\n",
      "    loss += self._evaluate_using_minibatch(network, self._current_minibatch) / self._num_minibatches\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\supervisedne.py\", line 264, in _evaluate_using_minibatch\n",
      "    yhat = network(x)\n",
      "           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_9976\\2304762305.py\", line 67, in forward\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_9976\\2304762305.py\", line 25, in forward\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same\n",
      "2023-08-31 23:27:58,922\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::EvaluationActor.call()\u001b[39m (pid=31364, ip=127.0.0.1, actor_id=97fa042572b257b38f846bca01000000, repr=<evotorch.core.EvaluationActor object at 0x000001972475C250>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 185, in call\n",
      "    return getattr(self._problem, method_name)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 3074, in _sample_and_compute_gradients\n",
      "    resulting_batch = sample_evaluated_batch()\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 3067, in sample_evaluated_batch\n",
      "    self.evaluate(batch)\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 2395, in evaluate\n",
      "    self._evaluate_all(batch)\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 2413, in _evaluate_all\n",
      "    self._evaluate_batch(batch)\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\supervisedne.py\", line 345, in _evaluate_batch\n",
      "    return super()._evaluate_batch(batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 2447, in _evaluate_batch\n",
      "    self._evaluate(sln)\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\neproblem.py\", line 424, in _evaluate\n",
      "    fitnesses = evaluator(self.parameterize_net(parameters))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\supervisedne.py\", line 338, in _evaluate_network\n",
      "    loss += self._evaluate_using_minibatch(network, self._current_minibatch) / self._num_minibatches\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\supervisedne.py\", line 264, in _evaluate_using_minibatch\n",
      "    yhat = network(x)\n",
      "           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_9976\\2304762305.py\", line 67, in forward\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_9976\\2304762305.py\", line 25, in forward\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same\n",
      "2023-08-31 23:27:58,946\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::EvaluationActor.call()\u001b[39m (pid=27024, ip=127.0.0.1, actor_id=9e890140728134c11ecfbcc301000000, repr=<evotorch.core.EvaluationActor object at 0x000001CF7FCBC190>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 185, in call\n",
      "    return getattr(self._problem, method_name)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 3074, in _sample_and_compute_gradients\n",
      "    resulting_batch = sample_evaluated_batch()\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 3067, in sample_evaluated_batch\n",
      "    self.evaluate(batch)\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 2395, in evaluate\n",
      "    self._evaluate_all(batch)\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 2413, in _evaluate_all\n",
      "    self._evaluate_batch(batch)\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\supervisedne.py\", line 345, in _evaluate_batch\n",
      "    return super()._evaluate_batch(batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 2447, in _evaluate_batch\n",
      "    self._evaluate(sln)\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\neproblem.py\", line 424, in _evaluate\n",
      "    fitnesses = evaluator(self.parameterize_net(parameters))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\supervisedne.py\", line 338, in _evaluate_network\n",
      "    loss += self._evaluate_using_minibatch(network, self._current_minibatch) / self._num_minibatches\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\supervisedne.py\", line 264, in _evaluate_using_minibatch\n",
      "    yhat = network(x)\n",
      "           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_9976\\2304762305.py\", line 67, in forward\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_9976\\2304762305.py\", line 25, in forward\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same\n",
      "2023-08-31 23:27:58,950\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::EvaluationActor.call()\u001b[39m (pid=15768, ip=127.0.0.1, actor_id=ec842f8f74d2885b086432b201000000, repr=<evotorch.core.EvaluationActor object at 0x000001F4AF18C250>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1424, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1364, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 726, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 464, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 185, in call\n",
      "    return getattr(self._problem, method_name)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 3074, in _sample_and_compute_gradients\n",
      "    resulting_batch = sample_evaluated_batch()\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 3067, in sample_evaluated_batch\n",
      "    self.evaluate(batch)\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 2395, in evaluate\n",
      "    self._evaluate_all(batch)\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 2413, in _evaluate_all\n",
      "    self._evaluate_batch(batch)\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\supervisedne.py\", line 345, in _evaluate_batch\n",
      "    return super()._evaluate_batch(batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\core.py\", line 2447, in _evaluate_batch\n",
      "    self._evaluate(sln)\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\neproblem.py\", line 424, in _evaluate\n",
      "    fitnesses = evaluator(self.parameterize_net(parameters))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\supervisedne.py\", line 338, in _evaluate_network\n",
      "    loss += self._evaluate_using_minibatch(network, self._current_minibatch) / self._num_minibatches\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\evotorch\\neuroevolution\\supervisedne.py\", line 264, in _evaluate_using_minibatch\n",
      "    yhat = network(x)\n",
      "           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_9976\\2304762305.py\", line 67, in forward\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_9976\\2304762305.py\", line 25, in forward\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Asus\\anaconda3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same\n"
     ]
    }
   ],
   "source": [
    "searcher.run(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f611654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
